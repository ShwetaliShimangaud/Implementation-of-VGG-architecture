{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip  '/content/drive/MyDrive/imagenette2-320.zip'"
      ],
      "metadata": {
        "id": "F2qoGkSanTQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra38ZknpmNM_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def read_dataset(path, size):\n",
        "    # Define image data generator with augmentation options if needed\n",
        "    image_generator = ImageDataGenerator()\n",
        "\n",
        "    # Set up the image generator to flow from the directory\n",
        "    batch_size = 32\n",
        "    image_size = (size, size)  # adjust the size as needed\n",
        "    class_mode = 'categorical'  # or 'binary' if it's a binary classification\n",
        "\n",
        "    # Flow images in batches from the directory\n",
        "    data_generator = image_generator.flow_from_directory(\n",
        "        path,\n",
        "        target_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode\n",
        "    )\n",
        "    return data_generator\n",
        "\n",
        "\n",
        "def get_train_dataset(size):\n",
        "    path = '/content/imagenette2-320/train'\n",
        "    return read_dataset(path, size)\n",
        "\n",
        "\n",
        "def get_validation_dataset(size):\n",
        "    path = '/content/imagenette2-320/val'\n",
        "    return read_dataset(path, size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset_loader\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#Number of label classes\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu',\n",
        "                 kernel_initializer='uniform'))\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(4096, (7, 7), activation='relu', padding='same'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Conv2D(4096, (1, 1), activation='relu', padding='same'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Conv2D(10, (1, 1), activation='softmax'))\n",
        "model.add(tf.keras.layers.GlobalMaxPooling2D())\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "# Create a new model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=[keras.metrics.TopKCategoricalAccuracy(k=1, name='top 1%'), keras.metrics.TopKCategoricalAccuracy(k=5, name='top 5%')])\n",
        "epochs = 25\n",
        "\n",
        "# Experiment 1 VGG-21 model S=256 Q = 256\n",
        "train_data = get_train_dataset(256)\n",
        "test_data = get_validation_dataset(256)\n",
        "score = model.fit(train_data,validation_data=test_data, epochs=epochs)\n"
      ],
      "metadata": {
        "id": "vxRWUHL-nNCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = score.history['top 1%']\n",
        "validation_accuracy = score.history['val_top 1%']\n",
        "epochs = [i for i in range(1, len(validation_accuracy)+1)]"
      ],
      "metadata": {
        "id": "iS6zZi3WBZ9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the curves\n",
        "plt.plot(epochs, train_accuracy, label='Train')\n",
        "plt.plot(epochs, validation_accuracy, label='Validation')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "DQIf3_5cBKIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}